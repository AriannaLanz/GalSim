\documentclass[preprint]{aastex}

% packages for figures
\usepackage{graphicx}
% packages for symbols
\usepackage{latexsym,amssymb,hyperref}
% AMS-LaTeX package for e.g. subequations
\usepackage{amsmath}


\usepackage[OT2,T1]{fontenc}


%=====================================================================
% FRONT MATTER
%=====================================================================

\slugcomment{Draft \today}

%=====================================================================
% BEGIN DOCUMENT
%=====================================================================

\newcommand{\klim}{\ensuremath{k_\mathrm{lim}}}
\newcommand{\kmax}{\ensuremath{k_\mathrm{max}}}
\newcommand{\kmin}{\ensuremath{k_\mathrm{min}}}
\newcommand{\rmd}{\ensuremath{\mathrm{d}}}
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}
\newcommand{\mi}{{\rm i}}
\newcommand{\me}{{\rm e}}

\DeclareSymbolFont{cyrletters}{OT2}{wncyr}{m}{n}
\DeclareMathSymbol{\Sha}{\mathalpha}{cyrletters}{"58}

\begin{document}

\title{The GalSim lensing engine}

\begin{abstract}
This document describes the GalSim ``lensing engine'' for drawing
shears randomly according to a user-specified shear power spectrum.
It includes a brief description of the theory behind shear power
spectra, the connection between the usual continuous description of
the theory versus our representation in terms of the discrete Fourier
transform, and a validation of the outputs for several test cases.
\end{abstract}

\tableofcontents

\section{Introduction}

The lensing engine (in galsim/lensing.py) is the part of GalSim that
is supposed to draw shears randomly according to a user-specified
power spectrum.  In this document, we begin with a brief description
of the theory behind shear power spectra, and then clarify the following
issues:
\begin{enumerate}
\item How does the discrete representation that we use (on a grid)
  relate to the standard formulation of the theory, which uses
  continuous representations?  (\S\ref{S:discrete})
\item Are our outputs consistent with expectations?
\begin{itemize}
\item How does it compare with another standard piece of software that
  generates shears using a different formalism? (\S\ref{S:comparison})
\item Is the normalization (expressed as a variance) correct? (\S\ref{S:testvar})
\item Does the variance behave appropriately when the grid size and
  spacing is changed? (\S\ref{S:testvar})
\item Does the full $P(k)$ of the shears that were generated agree
  with our expectations?  Does the result behave appropriately when
  the grid size and spacing is changed? (\S\ref{S:testpk})
\item Is the behavior appropriate when inputting only $E$ mode power,
  only $B$ mode power, and both $E$ and $B$ mode power? (\S\ref{S:testpk})
\end{itemize}
\item We should consider the impact of our current choice to force
  $P(k=0)=0$, which effectively says there is no cosmic variance. (\S\ref{S:pk0})
\end{enumerate}


\section{Theory}\label{sect:theory}

The lensing engine requires a shear power spectrum, $P(k)$.  We are
working in the flat-sky limit, so when we see expressions in terms of
$\ell$ we can swap $\ell$ with $k$ and $C_\ell$ with $P$, and
\beq
\Delta^2 = \frac{\ell(\ell+1) C_{\ell}}{2\pi}\equiv \frac{k^2 P(k)}{2\pi}.
\eeq
When people plot shear power spectra they usually actually plot
$\Delta^2(k)$ (or, in terms of the full-sky formalism, they plot $\ell(\ell+1)C_\ell/(2\pi)$).

If we identify pairs of galaxies and get the shears in a coordinate
system defined along the vector connecting them ($\gamma_+$) and at 45
degrees with respect to it ($\gamma_\times$), then we can compute
correlation functions of the $\gamma_+$ and $\gamma_\times$ values,
which we will call $\xi_{++}$ and $\xi_{\times\times}$.  Then the
standard cosmological correlation functions $\xi_{\pm}$ are defined as
\begin{align}
\xi_{\pm}(\theta) &=  \xi_{++}\pm \xi_{xx} \\
 &= \frac{1}{2\pi}\int k\,\rmd k P(k) J_{0/4}(k\theta).  \label{eq:xi}
\end{align}

Since correlation functions are dimensionless, we immediately see that
$P(k)$ has dimensions of angle$^2$ and $\Delta^2(k)$ is dimensionless.

The variance of the shear values, 
\beq
\mathrm{Var}(\gamma) = \langle g_1^2 + g_2^2\rangle,
\eeq
is essentially $\xi_+(\theta=0)$.   Note that this is what we get for
the defined $\xi_+$ in the limit of $\theta$ going to zero, but that
equation was defined in terms of $\gamma_+$ and $\gamma_\times$ rather
than $\gamma_1$ and $\gamma_2$.  On a grid, it's not clear that we
can enforce/check behavior of Var($\gamma_1$) or Var($\gamma_2)$,
particularly if the corners are important (which will be the case if
there is a lot of shear power at small $k$), probably we should 
 only expect normal behavior for Var($\gamma$), but it's still worth
 verifying this.  So, combining several equations,
\beq\label{E:shearvar}
\mathrm{Var}(\gamma) = \frac{1}{2\pi}\int_0^{\infty} k\,\rmd k P(k).
\eeq
which essentially says the shear variance is the power integrated over
the allowed area in $k$ space.  For the purpose of later calculations
of power spectra for gridded quantities, it is more useful to think in
terms of the 2d integral
\beq\label{E:alt-shearvar}
\mathrm{Var}(\gamma) = \frac{1}{(2\pi)^2} \int_{-\infty}^{\infty} \rmd k_x \rmd k_y
P(k_x, k_y).
\eeq

Alternatively, thinking ahead to when we will have a limited $k$
range, we can rewrite this as
\beq\label{E:alt-shearvar-limit}
\mathrm{Var}(\gamma) = \frac{4}{(2\pi)^2} \int_{\kmin}^{\kmax} \rmd
k_x \rmd k_y P(k).
\eeq
Here the factor of $4$ is meant to compensate for the other four
quadrants that are not represented explicitly (i.e., negative $k_x$
and/or $k_y$ values).

In the limit that our power spectrum doesn't have much power at
\kmax, Eq.~\ref{E:shearvar}, \ref{E:alt-shearvar}, and
\ref{E:alt-shearvar-limit} should all give essentially the same answer.

Our
grid is defined by
\begin{align}
L &= \mbox{length of grid along one dimension (angular units)}\\
d &= \mbox{spacing between grid points (angular units)}\\
N &= \mbox{number of grid points along one dimension} = L/d
\end{align}

Given this grid, our $\kmax=2\pi/d$.  The \kmin\ depends on whether
we are thinking about one dimension or two; it's either $2\pi/L$ or
$2\pi/(\sqrt{2}L)$.  When integrating along the grid we use the former.

In all of the above I have simply written $P(k)$ but in principle there can be
two such functions, $P_{E}$ and $P_B$.  I believe these
should simply be summed in the above variance equation, but should check this.

\section{Representing continuous fields using the Discrete Fourier Transform}\label{S:discrete}

Here is what Barney has managed to learn about this issue, and how we
are numerically representing $P(k)$, in the course of many pages of
handwritten derivation (much of which is of course now scribbled out).

\subsection{Conventions}

The definition of the correlation function in equation \eqref{eq:xi}
employs the \emph{angular frequency, non-unitary}\footnote{According
  to the paradigm setup in
  http://en.wikipedia.org/wiki/Fourier\_transform\#Other\_conventions}
definition of the (1D) Fourier transform:
\begin{eqnarray}
\tilde{f}(k) & = & \int_{-\infty}^{\infty} f(x) \me^{-\mi k x}
dx ~ ~ \equiv ~ \mathcal{F} \{ f(x) \} \label{eq:fwdft} ; \\
f(x) & = & \frac{1}{2 \pi} \int_{-\infty}^{\infty} \tilde{f}(k) \me^{\mi k x}
dk ~ ~ \equiv ~ \mathcal{F}^{-1}\{ \tilde{f}(k) \} \label{eq:invft}, 
\end{eqnarray}
with the usual simple generalizations to two or more dimensions.

The standard results in Discrete Fourier Transform (DFT) and its
halfway-house the Discrete Time Fourier Transform (DTFT) are all
derived under the unitary (i.e. symmetric with no odd factors of $2
\pi$ around) convention in the online literature, adding to the complexity of
interpretation.  This led me to re-derive some standard results of
Fourier theory using the conventions above, which it now makes sense
to state as we will require them in Section \ref{sect:DFTPS}.

\subsection{Fourier transform properties}
It can be readily shown that if we define $g(x L) \equiv f(x)$ the following well-known identity holds
under our Fourier transform convention:
\begin{equation}
\mathcal{F}\{g(x L)\} = \frac{1}{L}
\tilde{g}\left(\frac{k}{L}\right). \label{eq:gmult}
\end{equation}
If we further define $s(h + x) \equiv g(x)$ then it is straightforward
to show that
\begin{equation}
\mathcal{F}\{ s(h + x) \} = \me^{\mi k h} \tilde{s}(k).  \label{eq:sadd}
\end{equation}
Here we begin to get divergent results between conventions: there is
an additional factor of $2\pi$ in the exponent for the normal frequency
convention version of this property.

The most important result for approximating continuous functions using
DFTs is the Poisson summation formula, which under our conventions may
be stated as
\begin{equation}
\sum_{n=-\infty}^{\infty} f(n) = \sum_{q=-\infty}^{\infty} \tilde{f}(2
\pi q)
\end{equation}
for integers $n$ and $q$.  This result can be derived by writing the
  expression for the inverse Fourier transform of $\tilde{f}(2 \pi
q)$ and considering the Fourier series expansion of the periodic Dirac comb
function
\begin{equation}
\Sha_L (x) = \sum_{n=-\infty}^{\infty} \delta(x - nL).
\end{equation}
It should be noted that in the normal frequency, unitary transform
convention form of the Poisson summation formula the $2\pi$ within $\tilde{f}(2 \pi
q)$ is absent.\footnote{Barney would heartily welcome \emph{anyone} wishing to
check his derivations of these results using the non-symmetric
convention!}  Using equation \eqref{eq:gmult} we then find
\begin{equation}
\sum_{n=-\infty}^{\infty} f(n L) = \frac{1}{L}
\sum_{q=-\infty}^{\infty} \tilde{f} \left(\frac{2 \pi q}{L} \right),
\end{equation}
which can be modified further using equation \eqref{eq:sadd} to give
the most useful expression of the Poisson summation formula:
\begin{equation}
\sum_{n=-\infty}^{\infty} f(n L + x) = \frac{1}{L}
\sum_{q=-\infty}^{\infty} \tilde{f} \left(\frac{2 \pi  q}{L} \right)
\me^{\mi 2 \pi x q / L}.
\end{equation}
If we define $\Delta k \equiv k_{\rm min} = 2 \pi / L$ we can also write
this as
\begin{equation}
\sum_{n=-\infty}^{\infty} f\left(\frac{2\pi n}{\Delta k} + x \right) = 
\left(\frac{\Delta k}{2 \pi} \right)
\sum_{q=-\infty}^{\infty} \tilde{f} \left(q \Delta k \right)
\me^{\mi x \Delta k q }. \label{eq:poisson}
\end{equation}
These results give us most of what we need to understand DFTs with the
non-standard Fourier transform convention commonly adopted for weak
lensing power spectra in the flat sky approximation.

\subsection{The Fourier transform of discrete samples of the power spectra}\label{sect:DFTPS}
In what follows we are going to derive results only for the $\xi_+$
correlation function of equation \eqref{eq:xi}.  This will not
not impact upon the understanding of how $P(k)$ is approximated using DFTs,
but allows us to replace $\xi_{\pm}$ and $J_{0/4}(k \theta) $in
equation \eqref{eq:xi} with $\xi$ and $J_0$, respectively.  We will
just be aware subsquently that real ellipticity fields have two
components, to be treated as described by equation \eqref{eq:xi}.

The inverse Fourier transform of $P(k)$ to give $\xi_+(\theta)$ may 
be written in Cartesian coordinates as
\begin{equation}
\xi_{+}(\theta_1, \theta_2)  = \frac{1}{(2 \pi)^2} \int \! \! \!
\int_{-\infty}^{\infty} P(k_1, k_2) ~ \me^{\mi (k_1 \theta_1 + k_2
  \theta_2)} dk_1 dk_2. \label{eq:xip}
\end{equation}
The relation between this and equation \eqref{eq:xi} makes use of Bessel's first
integral:
\begin{equation}
J_n(z) = \frac{\mi^{-n}}{\pi} \int_0^{\pi} \me^{\mi z \cos{\theta}}
\cos{(n \theta)} d \theta,  
\end{equation}
(\emph{which I believes shows you have the correct expression for the
  variance on page 2, Rachel...}).

What happens if we only have finite samples of $P(k_1, k_2)$?  To
answer that, let us define the following function:
\begin{equation}
P_{\Delta k} [q, p] \equiv (\Delta k)^2 P(q \Delta k, p \Delta k).
\end{equation}
As here, we will use square brackets to denote functions with discrete input
variables throughout what follows.  We will also use indices $n, m$ in
real space summations and $q, p$ in Fourier space ($i,j$ are awkward
due to the common notations for $\sqrt{-1}$).  Let us also define the 2D Dirac
comb function in Fourier space
\begin{equation}
\Sha^2_{\Delta k} (k_1, k_2) = \sum_{q = -\infty}^{\infty} \delta(k_1
- q \Delta k) \sum_{p = -\infty}^{\infty} \delta(k_2
- p \Delta k).
\end{equation}
It can then be shown that
\begin{eqnarray}
\mathcal{F}^{-1} \left\{ P_{\Delta k} [q, p] \cdot  \Sha^2_{\Delta k} (k_1,
  k_2) \right\} & = & \mathcal{F}^{-1} \left\{ P(k_1, k_2) \cdot  (\Delta
  k)^2 \Sha^2_{\Delta k} (k_1,
  k_2) \right\}  \nonumber  \\
 & = & \mathcal{F}^{-1} \left\{ P(k_1, k_2) \right\} * \mathcal{F}^{-1} \left\{  (\Delta
  k)^2 \Sha^2_{\Delta k} (k_1, k_2) \right\} \nonumber \\
 & = & \xi_+(\theta_1, \theta_2 )  * \left\{ \sum_{n = -\infty}^{\infty} \delta\left(\theta_1
- \frac{2 \pi n}{\Delta k} \right) \sum_{m = -\infty}^{\infty}
\delta\left( \theta_2
- \frac{2 \pi m}{\Delta k} \right)  \right\} \nonumber \\
& = & = \sum_{n,m=-\infty}^{\infty} \xi_+\left(\theta_1
- \frac{2 \pi n}{\Delta k},  \theta_2
- \frac{2 \pi m}{\Delta k} \right) \label{eq:xisum}
\end{eqnarray}
Here we have again made use of the Fourier series expression for the
Dirac comb function, and employed the convolution theorem (convolution
denoted with $*$).  We note that the final expression \eqref{eq:xisum}
is still continuous, but describes an infinite, periodic summation (of period $L = 2 \pi
/ \Delta k$) of copies of the correlation function $\xi_+$.  For sufficiently small
$\Delta k$, these copies may be well-enough spaced in the real domain to
learn much about $\xi_+(\theta_1, \theta_2)$ in the non-overlapping
regions.

We therefore define this function as
\begin{equation}
\xi_{\frac{2\pi}{\Delta k}}(\theta_1, \theta_2) \equiv \sum_{n = -\infty}^{\infty} \xi_+\left(\theta_1
- \frac{2 \pi n}{\Delta k},  \theta_2
- \frac{2 \pi m}{\Delta k} \right).
\end{equation}
Using the expression of the Poisson summation formula in equation
\eqref{eq:poisson}, we can also write the result
\begin{equation}
\xi_{\frac{2\pi}{\Delta k}}(\theta_1, \theta_2) =
\sum_{q,p=-\infty}^{\infty} \left( \frac{\Delta k}{2 \pi} \right)^2 P(q \Delta k, p \Delta k) \me^{\mi \Delta
  k (\theta_1 q + \theta_2 p)} = \frac{1}{( 2 \pi)^2}
\sum_{q,p=-\infty}^{\infty} P_{\Delta k} [q, p] \me^{\mi \Delta
  k (\theta_1 q + \theta_2 p)}. \label{eq:dtft}
\end{equation}
This is the expression for the inverse of what is known as the
Discrete Time Fourier Transform (DTFT), although this result is
normally derived using unitary conventions for the transform pair.
Note that the terms $P_{\Delta k}[q, p]$ are dimensionless, being
composed of $(\Delta k)^2 = (2 \pi / L)^2$ multiplied by the samples $P(q \Delta k, p \Delta
k)$ of the power $P(k_1, k_2)$ (dimensions angle$^2$).  

One intuitive way of looking at the approximation of equation \eqref{eq:xip} for the case of discretely
sampled $P(k_1, k_2)$ is that the terms in the discrete sum should be
considered as \emph{impulses} of area $(\Delta k)^2$ and height $P(q \Delta k, p \Delta k)$.

\subsection{The Fourier transform of discrete, finite samples of the power spectra}
The expression in equation \eqref{eq:dtft} is periodic with period $2
\pi / \Delta k = L$.  All of the information it contains about
$\xi(\theta_1, \theta_2)$ is therefore also contained in one period
of the function only.  For approximating this information discretely, as desired in
numerical analysis, we can imagine taking $N$ equally spaced samples of
the function in equation \eqref{eq:dtft} along a single period $L$ in each
dimension (leading to $N^2$ samples total since we are working in 2D).
These samples are therefore separated by $\Delta \theta = 2 \pi /
\Delta k N = d$ in real space, and we define the sampled
function itself as
\begin{equation}
\xi_{\Delta \theta}[n, m] \equiv \xi_{\frac{2 \pi}{\Delta
    k}} \left( n \Delta \theta, m \Delta \theta \right) = \frac{1}{( 2 \pi)^2}
\sum_{q,p=-\infty}^{\infty} P_{\Delta k} [q, p] \me^{\mi 2 \pi (qn +
  pm) / N},
\end{equation}
for the integer indices $n, m = 0, 1, \ldots, N-1$, by substitution into equation
\eqref{eq:dtft}.  Using the periodicity of the exponential term in the
expression above, this may be written as
\begin{equation}
\xi_{\Delta \theta}[n, m] = \frac{1}{( 2 \pi)^2}
\sum_{q,p=0}^{N-1} P_N [q, p] \me^{\mi 2 \pi (qn +
  pm) / N}
\end{equation}
where we have defined
\begin{equation}
P_N[q, p] \equiv \sum_{i,j=-\infty}^{\infty}  P_{\Delta k} [q - i N, p
- j N] .
\end{equation}
Needless to say, in order to be able to calculate the values of
$P_N[q, p]$ in practice we must also truncate the 
$P_{\Delta k}$ sequence to be finite in length.  A \emph{very} common
choice is to use the same number $N$ of samples in both real and
Fourier space: this is also efficient, as it allows the direct use of
the Fast Fourier Transform algorithm.  We will say a little more about
this below.

Choosing to use only $N$
samples from $P_{\Delta k}$ then gives us a somewhat more
familiar expression for the inverse Discrete Fourier Transform (DFT),
written here for the non-unitary Fourier transform convention:
\begin{equation}
\xi_{\Delta \theta}[n, m] = \frac{1}{( 2 \pi)^2}
\sum_{q,p=0}^{N-1} P_{\Delta k} [q, p] \me^{\mi 2 \pi (qn +
  pm) / N}. \label{eq:dft}
\end{equation}
The overwhelmingly more common definition of the inverse DFT, and that adopted by
NumPy, instead reads as:
\begin{equation}
f[n, m] = \texttt{numpy.fft.ifft2}\left(\tilde{f}[p, q]\right) \equiv \frac{1}{N^2}
\sum_{q,p=0}^{N-1} \tilde{f}[q, p] \me^{\mi 2 \pi (qn +
  pm) / N} ,~~~~ (\textrm{NumPy convention}) \label{eq:dftnumpy}
\end{equation}
where the factor of $1/N^2$ is a convention commonly found in DFT
implementations, and ensures
that the DFT followed by the inverse DFT yields the original, input array.

We must use the convention of equation \eqref{eq:dftnumpy} for
performing the calculation within the code, and so this means that we
must attempt to account for the factors of $2 \pi$, $N$ and $\Delta
k$ ourselves.  Let us begin with the user specifying the
key dimensions of the problem $L$ and $d = \Delta \theta$ at the
outset, as assumed in Section \ref{sect:theory}, sensibly chosen (of
course) so that $N=L/\Delta \theta$ is an integer.  These choices also
set $\Delta k = 2 \pi / L$.  Beginning with equation
\eqref{eq:dft}, we may re-express the convenient $P_{\Delta k}[q, p]$ as
samples of the the dimensional $P(k_1, k_2)$ once again:
\begin{eqnarray}
\xi_{\Delta \theta}[n, m] & = & \frac{1}{( 2 \pi)^2}
\sum_{q,p=0}^{N-1} P_{\Delta k} [q, p] \me^{\mi 2 \pi (qn +
  pm) / N}  \\ & = & \frac{1}{(2 \pi)^2} \times \frac{(2 \pi)^2}{L^2}
 \sum_{q,p=0}^{N-1} P(q \Delta k, p \Delta k) \me^{\mi 2 \pi (qn +
  pm) / N} \\
& = & \frac{1}{L^2} \sum_{q,p=0}^{N-1} P(q \Delta k, p \Delta k) \me^{\mi 2 \pi (qn +
  pm) / N} \\
& = & \texttt{numpy.fft.ifft2}\left[P(q \Delta
  k, q \Delta k) / (\Delta \theta)^2\right].
\end{eqnarray}
This seems to agree with Rachel's empirical finding that taking the
output ellipticities of the original code, which scale in amplitude as the square root of
of the power/correlation function, we must further divide by a factor
$d = \Delta \theta$ to generate the output we expect.  Of course, I may
easily be missing factors of $N$ or $2 \pi $ about the place, so I
welcome anyone wishing to quickly scan through these steps I followed!

Finally, we said we would say little more about the implications of
the choice to use $N$ as the
number of samples in \emph{both} real and Fourier space, the final step in
arriving at equation \eqref{eq:dft}.  This choice ensures the
close interrelation of $N$, $L$ and the grid spacings $\Delta \theta$,
$\Delta k$.  The use of discrete, periodic sampling to represent
continuous, non-periodic functions is only an approximation, and
one that depends heavily on good choices of these interrelated sampling
parameters.

The two effects that must be minimized for a good approximation are of course
aliasing and unwanted
`overlapping' of functions in either real or Fourier space due to the
sampled, periodic
representation inherent in the DFT.  Adequately sampling our functions, and zero-padding
them where possible to artificially extend $L$, are the primary
strategies for making the DFT and its inverse a good approximation to
the Fourier transforms of equations \eqref{eq:fwdft} and
\eqref{eq:invft}.


\section{Comparison software}\label{S:comparison}

We will compare against a completely independent piece of software,
Chris Hirata's spherical harmonic transform code which is described in
multiple papers (for example,
\href{http://adsabs.harvard.edu/abs/2004PhRvD..70j3501H}{Hirata
  et~al. 2004}).  This does not use the flat-sky
approach, but that should not be huge important of a difference even
for our $L=10$ deg.  It is something to bear in mind if we start
looking for agreement at a few \% level on the largest $\theta$ or
smallest $k$.  This software wants $C_\ell(\ell)$ as its inputs.

\section{Tests of variances}\label{S:testvar}

\subsection{General considerations}

Moreover, we need to be well-sampled in $k$ space, so we should not
use functions that do unreasonable things like $k^{-2}$.

\subsection{Variance for Gaussian $P(k)$}

Barney suggested a test case that is a Gaussian, i.e., $P(k) =
P_0 e^{-\sigma^2 k^2 / 2}$.  Here both $P_0$ and $\sigma^2$ both
are dimensions of angle$^2$.  By Eq.~\ref{E:alt-shearvar-limit}, this means that
\begin{align}
\mathrm{Var}(\gamma) &= \frac{4P_0}{(2\pi)^2} \left[\int_{\kmin}^{\kmax} 
e^{-\sigma^2 k^2/2} \,\rmd k\right]^2 \\
 &= \frac{P_0}{2\pi\sigma^2}\left[ Erf(\kmax\sigma/\sqrt{2}) - Erf(\kmin\sigma/\sqrt{2})\right]^2.
\end{align}

We use three grids. The first is the standard GREAT10 grid with $L=10$
degrees and $N=100$, so $d=0.1$ deg $=360$ arcsec.  I will define the
Gaussian such that there is essentially no power left at our \kmax,
which is $2\pi/d=0.0175$ arcsec$^{-1}$.  The second grid has the same
$d$ but only 50 grid points per dimension, so it covers $5$ degrees.
Using this grid lets us test for sensitivity to \kmin\ at fixed \kmax.
The third grid covers the original $L=10$ deg, but with $N=50$, so
$d=0.2$ deg $=720$ arcsec; this grid (compared to the first one) has
the same \kmin\ and different \kmax. We use $\sigma \kmax=5$ or
$\sigma=286.5$ 
arcsec for the first two grids; we want to keep the same condition on
$\sigma\kmax$ for the last grid, so in that case we use
$\sigma=573.0$; then $Erf(\kmax\sigma/\sqrt{2})=1$.  For the three cases, we have $\sigma\kmin=0.05$,
$0.1$, and $0.1$, or $Erf(\kmin\sigma/\sqrt{2})=0.04$, $0.08$,
$0.08$.  This means that with $P_0=1$, the predicted variances for the
three grids are $1.8\times 10^{-6}$, $1.8\times 10^{-6}$, and
$4.1\times 10^{-7}$ for the three grids.

The code is:
\begin{verbatim}
import galsim
import numpy as np
test_ps = galsim.PowerSpectrum(lambda k : np.exp(-0.5*((286.5*k)**2)))
g1, g2 = test_ps.buildGriddedShears(grid_spacing=360., ngrid=100)
print np.var(g1), np.var(g2), np.var(g1)+np.var(g2)
g1, g2 = test_ps.buildGriddedShears(grid_spacing=360., ngrid=50)
print np.var(g1), np.var(g2), np.var(g1)+np.var(g2)
test_ps = galsim.PowerSpectrum(lambda k : np.exp(-0.5*((573.0*k)**2)))
g1, g2 = test_ps.buildGriddedShears(grid_spacing=720., ngrid=50)
print np.var(g1), np.var(g2), np.var(g1)+np.var(g2)
\end{verbatim}

The results are around $1.9\times 10^{-6}$ in the first two cases, and
$4.6\times 10^{-7}$ in the last case.  So we have the right scaling
with the grid spacing and grid size, but the results are $\sim 6$--12\%
higher than predictions. Essentially, they are what you would expect
if the term with the Erf in it was 1, instead of a bit below 1 --
i.e., it's kind of acting like our \kmin\ is zero instead of the real
\kmin.

Note that the variance is nearly evenly divided between the two components.

\subsection{Variance for flat $P(k)$}

This test is dangerous because of the amount of large-scale power, so
we'll use a modified version of it.  Let's say $P(k)=P_0$ for
$k<$\klim\ arcmin$^{-1}$, where \klim\ is well below \kmax\ for all the
grids; and set $P$ to zero for all larger $k$. Using Eq.~\ref{E:alt-shearvar-limit}, we expect
\begin{align}
\mathrm{Var}(\gamma) &= \frac{4P_0}{(2\pi)^2}
\left[\int_{\kmin}^{\klim} \rmd k\right]^2 \\
 &= \frac{P_0}{\pi^2} \left(\klim-\kmin\right)^2.
\end{align}

For the set of grids from the previous test, \kmin\ is
$0.000175$, $0.00035$, and $0.000175$.  We will set $\klim=10\kmin$,
so we can write
\beq
\mathrm{Var}(\gamma) = \frac{81 P_0 \kmin^2}{\pi^2}.
\eeq
With $P_0=1$, we expect
shear variances that are $2.5\times 10^{-7}$, $1\times 10^{-6}$,
and $2.5\times 10^{-7}$.

The code is
\begin{verbatim}
import galsim
import numpy as np
def pfunc1(k):
    parr = np.zeros_like(k)
    parr[k<=0.00175] = 1.
    return parr
def pfunc2(k):
    parr = np.zeros_like(k)
    parr[k<=0.0035] = 1.
    return parr
test_ps1 = galsim.PowerSpectrum(pfunc1)
test_ps2 = galsim.PowerSpectrum(pfunc2)
g1, g2 = test_ps1.buildGriddedShears(grid_spacing=360., ngrid=100)
print np.var(g1), np.var(g2), np.var(g1)+np.var(g2)
g1, g2 = test_ps2.buildGriddedShears(grid_spacing=360., ngrid=50)
print np.var(g1), np.var(g2), np.var(g1)+np.var(g2)
g1, g2 = test_ps1.buildGriddedShears(grid_spacing=720., ngrid=50)
print np.var(g1), np.var(g2), np.var(g1)+np.var(g2)
\end{verbatim}

Since the variances are noisy, I averaged the results over 10000
realizations (this takes about 1min to run), and found $2.36\times
10^{-7}$, $9.45\times 10^{-7}$, and $2.36\times 10^{-7}$.  These are all
5\% below my naive calculation.  It seems possible that this is
because of some finite-gridding effect; rather than pursuing this
question further, I will investigate this question in the context of
the full $P(k)$ in the next section.

\section{Test of full $P(k)$}\label{S:testpk}

I have a WMAP7 LCDM prediction for the cosmic shear signal for a
sample with $z_{med}\sim 0.55$, which I can use as an input to both
the SHT code and ours.  Given the range of $\ell$ for which it is
defined, $2<\ell<2000$, we cannot use our standard grid because that
has $\kmax=3600$ radians$^{-1}$.  So, for this test I use a grid with
the same $L$ as before, but $N=50$ (i.e., $d$ gets doubled), which
means $\kmax=1800$ radians$^{-1}$.

Using the SHT code, I made gridded shears for each of 3 cases:
$P_E=P(k)$ and $P_B=0$; $P_B=P(k)$ and $P_E=0$; and $P_E=P_B=P(k)$ (5
realizations of each).
For GalSim, since it's less computationally expensive I averaged over
more realizations; for our code, it is crucial to inform the code that
the inputs have units of radians.

The python script test\_pk.py in devel/external/test\_gridshear/ does the following:
\begin{enumerate}
\item Generates shears according to this PS using GalSim.
\item Runs the GREAT10 power spectrum code on both (must flip sign of
  one shear component before doing so), and averages it over several
  noise realizations.
\end{enumerate}

The python script test\_pk\_sht.py in that directory does the following:
\begin{enumerate}
\item Manipulate outputs of the SHT code to be consistent with
  expectations (incl. one sign flip for e1).
\item Runs the GREAT10 power spectrum code on it.
\end{enumerate}

Finally, plot\_pk\_test.py in that directory plots the original and
simulated $P(k)$ based on these files.  The results for the three
cases (input $P_E$, input $P_B$, and input $P_E=P_B$) are in
Figures~\ref{F:pe}, \ref{F:pb}, \ref{F:peb}.  \textbf{These plots have
  all been updated to use the version of the lensing engine with the
  dimensionality fix mentioned in the intro to these notes.}

\begin{figure}
\begin{center}
\includegraphics[width=3in]{../external/test_gridshear/output/compare_input_pe.eps}
\caption{Output shear power spectra (plotted as the dimensionless
  $\Delta^2$) for the grids described in Sec.~\ref{S:testpk}, where
  the input $P_E$ is a realistic cosmological one (shown as the `theory' line on
  the plot) and the input $P_B=0$. The results for GalSim and the
  comparison SHT code are both plotted.\label{F:pe}}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=3in]{../external/test_gridshear/output/compare_input_pb.eps}
\caption{Output shear power spectra (plotted as the dimensionless
  $\Delta^2$) for the grids described in Sec.~\ref{S:testpk}, where
  the input $P_B$ is a theoretical one and the input $P_E=0$. The results for GalSim and the
  comparison SHT code are both plotted.\label{F:pb}}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
\includegraphics[width=3in]{../external/test_gridshear/output/compare_input_peb.eps}
\caption{Output shear power spectra (plotted as the dimensionless
  $\Delta^2$) for the grids described in Sec.~\ref{S:testpk}, where
  the input $P_E=P_B$ is shown as the `theory' line. The results for GalSim and the
  comparison SHT code are both plotted.\label{F:peb}}
\end{center}
\end{figure}

Conclusions:
\begin{itemize}
\item \textbf{The dimensionality fix, dividing by grid spacing, has
    gotten rid of nearly all discrepancies between theoretical and
    generated power spectra.}
\item SHT code: it gives roughly a consistent power spectrum compared
  to our inputs (modulo possible slight differences in scaling that
  may not be worth investigating until our own PS code is ready),
  though there are signs of $E$ vs. $B$ leakage in the case where one
  or the other is zero.
\item GalSim: we don't see $E$ vs. $B$ leakage at any significant
  level.  The amplitudes and scaling with $\ell$ are approximately
  correct.
\item The amplitude for the GalSim powerspectra is slightly below that
  for the SHT code.  It is worth investigating whether this is some
  finite-gridding effect on our part, which seems testable by
  increasing the grid spacing.
\item While the big-picture results seem good, there are some finer
  details that require investigation, in particular the fact that both
  codes seem to give steeper $P(k)$ than the theory.  Given how these
  tests were done, it could have to do with the $k$-space binning in
  the power spectrum estimator, the sizes of the bins, etc.  I'm not sure how much detail we want
  to dig into here, vs. waiting for our own power spectrum estimator.
  This is particularly true given that the SHT code was well-validated
  and exhibits nearly the same slope as the GalSim outputs.
\end{itemize}

The simplest possible test is simply to change the $\ell$ binning in
the PS estimation code.  This will let us see if we're running into
some finite-binning effects in the PS estimation.  The original
calculations had 20 $\ell$ bins; the new one uses 50 within the same
$\ell$ range.  To beat down the noise, I used 400 realizations of the
shears, instead of 20 as before.  The result is shown in
Fig.~\ref{F:pe-fine}.  It is clear that the results are, as compared
to Fig.~\ref{F:pe}, closer to the theory.  In particular, the
amplitude {\em and} slope are both close to theory for $\ell>100$.
Note that the jitter in that curve does not go away if we use more
realizations.  This could have to do with the exact locations of the
annular $\ell$ bins as compared to the finite $\ell$ modes that are
probed by our grid.  

Since it's hard to see how large differences between theory and the
GalSim results are, Fig.~\ref{F:pe-fine-ratio} shows the ratio between
the GalSim outputs and the theory.  For $\ell<100$, the results are
too low by $\sim 20$\%.  Above that, it seems to be 5\% too low, which
is suspiciously similar to the results of the variance tests.
However, this 5\% difference is better for the case with coarser
$\ell$ binning for the PS measurement, which 
suggests that for a user to realistically compare their output power
spectrum against the theoretical one, they {\em must} account for
the effects of finite $\ell$-binning on the theory.  Alternatively
they should choose rather fine $\ell$ bins to minimize the problem.
\begin{figure}
\begin{center}
\includegraphics[width=3in]{../external/test_gridshear/output/compare_input_pe.fine.eps}
\caption{Output shear power spectra (plotted as the dimensionless
  $\Delta^2$) for the grids described in Sec.~\ref{S:testpk}, where
  the input $P_E$ is a realistic cosmological one (shown as the `theory' line on
  the plot) and the input $P_B=0$. The results for GalSim and the
  comparison SHT code are both plotted, but for GalSim we used 50
  $\ell$ bins in the PS estimation, rather than 20 as in Fig.~\ref{F:pe}.\label{F:pe-fine}}
\end{center}
\end{figure}
\begin{figure}
\begin{center}
\includegraphics[width=3in]{../external/test_gridshear/output/compare_input_pe.fine.ratio.eps}
\caption{Ratio of GalSim EE PS vs. theory from Fig.~\ref{F:pe-fine}.\label{F:pe-fine-ratio}}
\end{center}
\end{figure}

\textbf{Need to test robustness to grid spacing and size, and whether
  the above could be some discreteness issue.}

\section{Shear power on larger scales than our grid}\label{S:pk0}

It's not clear that we should really be enforcing $P(0)=0$, i.e., no
power below our \kmin.  This is a valid condition for the full-sky
power spectrum, but will not in general be valid for a small patch of
the sky, due to sampling variance.  In order to include this sampling
variance, it would be preferable to assign $P(0)=$ some kind of
integral over $P(k<\kmin)$ (perhaps an average power in that $k$
range; details to be worked out later) assuming the power function is
defined for those value of $k$.  However, this limitation is only a
problem if we are checking quantities like the shear correlation
function or its value at $\theta=0$, i.e., the shear variance.  If we
are testing the ability to recover a power spectrum $P(k)$ defined at
the values of $k$ that are accessible to our grid, the $P(0)=0$
condition that we've imposed is irrelevant.

Nonetheless, we may wish to modify the lensing engine to check whether
the power function is defined for $0\le k\le\kmin$, and assign some
appropriately-weighted integral over that range as $P(k=0)$.

\end{document}
